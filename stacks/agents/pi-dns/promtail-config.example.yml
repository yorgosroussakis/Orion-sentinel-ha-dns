# Promtail Configuration for Pi DNS Agent
# Ships Pi-hole and Unbound logs to Dell CoreSrv Loki (SPoG mode)
#
# This configuration is designed for the Single Pane of Glass (SPoG) architecture
# where the Dell CoreSrv hosts centralized observability (Loki, Grafana, Prometheus)
#
# Setup Instructions:
# 1. Copy this file to promtail-config.yml
# 2. Update the Dell CoreSrv IP address in the clients URL below
# 3. Deploy using the docker-compose.yml in this directory
# 4. Ensure firewall allows traffic from Pi DNS to Dell port 3100

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  # Dell CoreSrv Loki endpoint - UPDATE THIS IP!
  - url: http://192.168.8.100:3100/loki/api/v1/push

    # Batching configuration for efficiency
    batchwait: 1s
    batchsize: 1048576  # 1MB

    # Retry configuration for network resilience
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10

    # Timeout
    timeout: 10s

    # Optional: Add authentication if Loki requires it
    # basic_auth:
    #   username: <username>
    #   password: <password>

scrape_configs:
  # Pi-hole Query Logs
  - job_name: pihole-queries
    static_configs:
      - targets:
          - localhost
        labels:
          job: pihole
          host: pi-dns
          stack: dns-ha
          component: dns-blocker
          __path__: /var/log/pihole/*.log

    pipeline_stages:
      # Parse Pi-hole query log format
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+)\s+(?P<query_type>\S+)\s+(?P<domain>\S+)\s+(?P<client>\S+)\s+(?P<action>\S+)'

      # Extract timestamp
      - timestamp:
          source: timestamp
          format: 'Jan _2 15:04:05'

      # Add labels for filtering
      - labels:
          query_type:
          action:

  # Pi-hole FTL Logs
  - job_name: pihole-ftl
    static_configs:
      - targets:
          - localhost
        labels:
          job: pihole-ftl
          host: pi-dns
          stack: dns-ha
          component: dns-blocker
          __path__: /var/log/pihole/FTL.log

    pipeline_stages:
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+)\s+(?P<severity>\S+):\s+(?P<message>.*)'

      - timestamp:
          source: timestamp
          format: 'Jan _2 15:04:05'

      - labels:
          severity:

  # Unbound DNS Resolver Logs
  - job_name: unbound
    static_configs:
      - targets:
          - localhost
        labels:
          job: unbound
          host: pi-dns
          stack: dns-ha
          component: dns-resolver
          __path__: /var/log/unbound/*.log

    pipeline_stages:
      - regex:
          expression: '^\[(?P<timestamp>[^\]]+)\]\s+unbound\[(?P<pid>\d+)\]:\s+\[(?P<thread>\d+)\]\s+(?P<level>\S+):\s+(?P<message>.*)'

      - timestamp:
          source: timestamp
          format: RFC3339

      - labels:
          level:

  # Keepalived High Availability Logs
  - job_name: keepalived
    static_configs:
      - targets:
          - localhost
        labels:
          job: keepalived
          host: pi-dns
          stack: dns-ha
          component: ha-manager
          __path__: /var/log/syslog

    pipeline_stages:
      # Only match Keepalived entries
      - match:
          selector: '{job="keepalived"}'
          stages:
            - regex:
                expression: '.*Keepalived.*'
            - regex:
                expression: '^(?P<timestamp>\S+\s+\S+\s+\S+)\s+(?P<hostname>\S+)\s+Keepalived.*:\s+(?P<message>.*)'
            - timestamp:
                source: timestamp
                format: 'Jan _2 15:04:05'
            - labels:
                hostname:

  # Docker Container Logs (from DNS stack containers)
  - job_name: docker-containers
    static_configs:
      - targets:
          - localhost
        labels:
          job: docker
          host: pi-dns
          stack: dns-ha
          __path__: /var/lib/docker/containers/*/*.log

    pipeline_stages:
      # Parse Docker JSON log format
      - json:
          expressions:
            stream: stream
            log: log
            time: time

      - timestamp:
          source: time
          format: RFC3339Nano

      - output:
          source: log

      # Extract container ID from path
      - regex:
          expression: '^/var/lib/docker/containers/(?P<container_id>[^/]+)/.*'
          source: filename

      - labels:
          container_id:
          stream:

  # System Logs (for correlation and debugging)
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: system
          host: pi-dns
          stack: dns-ha
          component: os
          __path__: /var/log/syslog

    pipeline_stages:
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+\s+\S+)\s+(?P<hostname>\S+)\s+(?P<service>\S+)(\[(?P<pid>\d+)\])?:\s+(?P<message>.*)'

      - timestamp:
          source: timestamp
          format: 'Jan _2 15:04:05'

      - labels:
          hostname:
          service:

      # Filter out noise
      - match:
          selector: '{job="system"}'
          action: drop
          drop_counter_reason: "noisy_service"
          stages:
            - regex:
                expression: '(CRON|systemd|dbus)'
                source: service

# Resource limits for Raspberry Pi
limits_config:
  readline_rate: 10000
  readline_burst: 20000
